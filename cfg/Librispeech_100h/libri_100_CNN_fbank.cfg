[cfg_proto]
cfg_proto = proto/global.proto
cfg_proto_chunk = proto/global_chunk.proto

[exp]
cmd = 
run_nn_script = run_nn
out_folder = exp/libri_100_CNN_fbank
seed = 1234
use_cuda = True
multi_gpu = False
save_gpumem = False
n_epochs_tr = 12

[dataset1]
data_name=train_clean_100
fea:fea_name=fbank
    fea_lst=/home/emre/data/librispeech/data/train_clean_100_fbank/feats.scp
    fea_opts=apply-cmvn --utt2spk=ark:/home/emre/data/librispeech/data/train_clean_100_fbank/utt2spk  scp:/home/emre/data/librispeech/data/train_clean_100_fbank/cmvn.scp ark:- ark:- | add-deltas --delta-order=2 ark:- ark:- |
    cw_left=5
    cw_right=5

    
lab:lab_name=lab_cd
    lab_folder=/home/emre/data/librispeech/exp/tri3b_train_clean_100_ali
    lab_opts=ali-to-pdf 
    lab_count_file=auto
    lab_data_folder=/home/emre/data/librispeech/data/train_clean_100_fbank/
    lab_graph=/home/emre/data/librispeech/exp/tri3b/graph/

N_chunks=50
        
[dataset2]
data_name=dev_clean
fea:fea_name=fbank
    fea_lst=/home/emre/data/librispeech/data/dev_clean_fbank/feats.scp
    fea_opts=apply-cmvn --utt2spk=ark:/home/emre/data/librispeech/data/dev_clean_fbank/utt2spk scp:/home/emre/data/librispeech/data/dev_clean_fbank/cmvn.scp ark:- ark:- | add-deltas --delta-order=2 ark:- ark:- |
    cw_left=5
    cw_right=5


lab:lab_name=lab_cd
    lab_folder=/home/emre/data/librispeech/exp/tri3b_dev_clean_ali
    lab_opts=ali-to-pdf 
    lab_count_file=auto
    lab_data_folder=/home/emre/data/librispeech/data/dev_clean_fbank/
    lab_graph=/home/emre/data/librispeech/exp/tri3b/graph/

N_chunks=8

[dataset3]
data_name=test_clean
fea:fea_name=fbank
    fea_lst=/home/emre/data/librispeech/data/test_clean_fbank/feats.scp
    fea_opts=apply-cmvn --utt2spk=ark:/home/emre/data/librispeech/data/test_clean_fbank/utt2spk scp:/home/emre/data/librispeech/data/test_clean_fbank/cmvn.scp ark:- ark:- | add-deltas --delta-order=2 ark:- ark:- |
    cw_left=5
    cw_right=5


lab:lab_name=lab_cd
    lab_folder=/home/emre/data/librispeech/exp/tri3b_test_clean_ali
    lab_opts=ali-to-pdf 
    lab_count_file=auto
    lab_data_folder=/home/emre/data/librispeech/data/test_clean_fbank/
    lab_graph=/home/emre/data/librispeech/exp/tri3b/graph/

N_chunks=8

        
[data_use]
train_with=train_clean_100
valid_with=dev_clean
forward_with=test_clean

[batches]
batch_size_train = 128
max_seq_length_train = 1000
increase_seq_length_train = False
start_seq_len_train = 100
multply_factor_seq_len_train = 2
batch_size_valid = 128
max_seq_length_valid = 1000

[architecture1]
arch_name = CNN_layers
arch_proto = proto/CNN.proto
arch_library = neural_networks
arch_class = CNN
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = False
cnn_n_filt = 120,60,60
cnn_len_filt = 10,3,3
cnn_max_pool_len = 2,2,1
cnn_use_laynorm_inp = False
cnn_use_batchnorm_inp = False
cnn_use_laynorm = False,False,False
cnn_use_batchnorm = True,True,True
cnn_act = relu,relu,relu
cnn_drop = 0.0,0.0,0.0
arch_lr = 0.08
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = sgd
opt_momentum = 0.0
opt_weight_decay = 0.0
opt_dampening = 0.0
opt_nesterov = False

[architecture2]
arch_name = MLP_layers
arch_proto = proto/MLP.proto
arch_library = neural_networks
arch_class = MLP
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = False
dnn_lay = 2048,2048,2048,2048,N_out_lab_cd
dnn_drop = 0.10,0.10,0.10,0.10,0.0
dnn_use_laynorm_inp = False
dnn_use_batchnorm_inp = False
dnn_use_batchnorm = True,True,True,True,False
dnn_use_laynorm = False,False,False,False,False
dnn_act = relu,relu,relu,relu,softmax
arch_lr = 0.08
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = sgd
opt_momentum = 0.0
opt_weight_decay = 0.0
opt_dampening = 0.0
opt_nesterov = False

[model]
model_proto = proto/model.proto
model = out_dnn1=compute(CNN_layers,fbank)
	out_dnn2=compute(MLP_layers,out_dnn1)
	loss_final=cost_nll(out_dnn2,lab_cd)
	err_final=cost_err(out_dnn2,lab_cd)

[forward]
forward_out = out_dnn2
normalize_posteriors = True
normalize_with_counts_from = lab_cd
save_out_file = False
require_decoding = True

[decoding]
decoding_script_folder=kaldi_decoding_scripts/
decoding_script=decode_dnn.sh
decoding_proto=proto/decoding.proto
min_active=200
max_active=7000
max_mem=50000000
beam=20.0
latbeam=12.0
acwt=0.10
max_arcs=-1
skip_scoring=false
scoring_script=/home/emre/data/kaldi/egs/librispeech/s5/local/score.sh
scoring_opts="--min-lmwt 4 --max-lmwt 23"
norm_vars=False
